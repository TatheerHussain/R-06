{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd288ec3",
   "metadata": {},
   "source": [
    "# Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0590ffad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# library\n",
    "import os\n",
    "#from pprint import pprint as pp\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import LongformerTokenizer, AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1daf2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c96c9b7",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57040781",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1121\n",
      "615\n",
      "\n",
      "1736\n",
      "561\n"
     ]
    }
   ],
   "source": [
    "first_dataset_doc_path = \"./dataset/First_Phase_Release(Correction)/First_Phase_Text_Dataset/\"\n",
    "second_dataset_doc_path = \"./dataset/Second_Phase_Dataset/Second_Phase_Text_Dataset/\"\n",
    "label_path = [\"./dataset/First_Phase_Release(Correction)/answer.txt\", \"./dataset/Second_Phase_Dataset/answer.txt\"]\n",
    "val_dataset_doc_parh = \"./dataset/validation_dataset/Validation_Release/\"\n",
    "val_label_path = \"./dataset/validation_dataset/answer.txt\"\n",
    "\n",
    "first_dataset_path = [first_dataset_doc_path + file_path for file_path in os.listdir(first_dataset_doc_path)]\n",
    "second_dataset_path = [second_dataset_doc_path + file_path for file_path in os.listdir(second_dataset_doc_path)]\n",
    "train_path = first_dataset_path + second_dataset_path\n",
    "val_path = [val_dataset_doc_parh + file_path for file_path in os.listdir(val_dataset_doc_parh)]\n",
    "\n",
    "#check number of data-path\n",
    "print(len(first_dataset_path)) #1120\n",
    "print(len(second_dataset_path)) #614\n",
    "print()\n",
    "print(len(train_path)) #1734\n",
    "print(len(val_path)) #560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8480e42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_label_dict(label_path):\n",
    "    \"\"\"\n",
    "    Read labeled data from a file and create dictionaries for training and validation datasets.\n",
    "\n",
    "    uses the `create_label_dict` function to read label files, addressing the potential UTF-8 BOM issue (U+FEFF) by using the `utf-8-sig` encoding.\n",
    "\n",
    "    # Function: create_label_dict\n",
    "\n",
    "    ## Description\n",
    "    This function reads a label file and creates a dictionary containing labeled data. It removes the UTF-8 BOM if present using the `utf-8-sig` encoding.\n",
    "\n",
    "    ## Parameters\n",
    "    - `label_path`: The path to the label file that needs to be processed.\n",
    "\n",
    "    ## Returns\n",
    "    - `label_dict`: A dictionary containing labeled data with unique IDs as keys and corresponding label information as values.\n",
    "    \"\"\"\n",
    "    label_dict = {}  # y\n",
    "    with open(label_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "        file_text = f.read().strip()  \n",
    "\n",
    "    # (id, label, start, end, query) or (id, label, start, end, query, time_org, timefix)\n",
    "    for line in file_text.split(\"\\n\"):\n",
    "        sample = line.split(\"\\t\")  \n",
    "        sample[2], sample[3] = int(sample[2]), int(sample[3])\n",
    "\n",
    "        if sample[0] not in label_dict:\n",
    "            label_dict[sample[0]] = [sample[1:]]\n",
    "        else:\n",
    "            label_dict[sample[0]].append(sample[1:])\n",
    "\n",
    "    return label_dict\n",
    "\n",
    "train_label_dict = create_label_dict(label_path[0])\n",
    "second_dataset_label_dict = create_label_dict(label_path[1])\n",
    "train_label_dict.update(second_dataset_label_dict)\n",
    "val_label_dict = create_label_dict(val_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49a7e34c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_medical_records(paths):\n",
    "    \"\"\"\n",
    "    Function to load medical records from text files and create dictionaries for training and validation datasets.\n",
    "\n",
    "    Description :\n",
    "    This function takes a list of file paths, reads the corresponding text files, and creates a dictionary containing medical records.\n",
    "    Each file is identified by its unique ID, extracted from the file path.\n",
    "\n",
    "    Parameters :\n",
    "    - `paths`: A list of file paths containing medical records.\n",
    "\n",
    "    Returns :\n",
    "    - `medical_record_dict`: A dictionary containing medical records, where file IDs are used as keys, and the corresponding text content is the value.\n",
    "    \"\"\"\n",
    "    medical_record_dict = {}\n",
    "    for data_path in paths:\n",
    "\n",
    "        if os.path.isfile(data_path):\n",
    "            file_id = data_path.split(\"/\")[-1].split(\".txt\")[0]\n",
    "            with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                file_text = f.read()\n",
    "                medical_record_dict[file_id] = file_text\n",
    "    return medical_record_dict\n",
    "\n",
    "train_medical_record_dict = load_medical_records(train_path)\n",
    "val_medical_record_dict = load_medical_records(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35459ba7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1734\n",
      "1734\n",
      "560\n",
      "560\n"
     ]
    }
   ],
   "source": [
    "#chect the number of data\n",
    "print(len(list(train_medical_record_dict.keys()))) #1734\n",
    "print(len(list(train_label_dict.keys()))) #1734\n",
    "print(len(list(val_medical_record_dict.keys()))) #560\n",
    "print(len(list(val_label_dict.keys()))) #560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b0e22e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04586974",
   "metadata": {},
   "source": [
    "### clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84411bc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_labels(text, labels, record_id, tag=False):\n",
    "    \"\"\"\n",
    "    Check if the extracted labels from the text match the expected labels.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The full text of the medical record.\n",
    "    - labels (list): A list of labels containing (id, start, end, expected_text).\n",
    "    - record_id (str): The identifier of the medical record.\n",
    "    - tag (bool): If True, print correct extractions as well.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    for i, label in enumerate(labels):  \n",
    "        extracted_text = text[label[1]:label[2]]\n",
    "        if extracted_text != label[3]:\n",
    "            print(f\"Error in ID {record_id}, Line {i}: {label[0]}, position: {label[1]}-{label[2]}, \"\n",
    "                  f\"label: '{label[3]}', extracted: '{extracted_text}'\")\n",
    "        elif tag:\n",
    "            print(f\"Correct in ID {record_id}, Line {i}: {label[0]}, position: {label[1]}-{label[2]}, extracted: '{extracted_text}'\")\n",
    "\n",
    "def check_all_labels(medical_records, label_dict, tag=False):\n",
    "    \"\"\"\n",
    "    Check labels for all medical records against the provided label dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - medical_records (dict): A dictionary with medical record IDs as keys and corresponding text as values.\n",
    "    - label_dict (dict): A dictionary with medical record IDs as keys and lists of labels as values.\n",
    "    - tag (bool): If True, print correct extractions as well.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    for record_id, text in medical_records.items():\n",
    "        if record_id in label_dict:\n",
    "            labels = label_dict[record_id]\n",
    "            check_labels(text, labels, record_id, tag)\n",
    "        else:\n",
    "            print(f\"ID: {record_id} has no label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c28bceb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in ID 1139, Line 16: HOSPITAL, position: 2702-2722, label: 'PLANTAGENET HOSPITAL', extracted: 'PLANTAGENE3/9 JENNIE'\n",
      "Error in ID 1481, Line 21: DEPARTMENT, position: 2390-2403, label: 'SEALS Central', extracted: 'SEAKALBARRI H'\n"
     ]
    }
   ],
   "source": [
    "# check training data\n",
    "check_all_labels(train_medical_record_dict, train_label_dict)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf5d00ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLANTAGENE3/9 JENNIE\n",
      "['HOSPITAL', 2702, 2722, 'PLANTAGENET HOSPITAL']\n"
     ]
    }
   ],
   "source": [
    "# check 1139, PLANTAGENET 3/9 JENNIE COX CLOSE Pathology ?\n",
    "print(train_medical_record_dict['1139'][2702:2722])\n",
    "print(train_label_dict['1139'][16])\n",
    "\n",
    "# replace it\n",
    "train_label_dict['1139'][16][3]=train_medical_record_dict['1139'][2702:2722]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6ac8e36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEAKALBARRI H\n",
      "['DEPARTMENT', 2390, 2403, 'SEALS Central']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['DEPARTMENT', 2390, 2403, 'SEALS Central']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check 1481, there is no DEPARTMENT\n",
    "print(train_medical_record_dict['1481'][2390:2403])\n",
    "print(train_label_dict['1481'][21])\n",
    "\n",
    "# remove it \n",
    "train_label_dict['1481'].pop(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be901a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in ID file21297, Line 20: ORGANIZATION, position: 6045-6064, label: 'KB Home Los Angeles', extracted: 'KB Home\tLos Angeles'\n"
     ]
    }
   ],
   "source": [
    "# check val data\n",
    "check_all_labels(val_medical_record_dict, val_label_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19235f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check file21297, index 6047 is '\\t'\n",
    "val_medical_record_dict['file21297'][6045:6064]\n",
    "\n",
    "# replace it\n",
    "val_medical_record_dict['file21297'] = val_medical_record_dict['file21297'][:6047] + ' ' + val_medical_record_dict['file21297'][6048:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959e63f0",
   "metadata": {},
   "source": [
    "### create label type table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3224d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OTHER': 0, 'ROOM': 1, 'STREET': 2, 'IDNUM': 3, 'TIME': 4, 'DATE': 5, 'MEDICALRECORD': 6, 'PHONE': 7, 'AGE': 8, 'URL': 9, 'ZIP': 10, 'COUNTRY': 11, 'DURATION': 12, 'HOSPITAL': 13, 'PATIENT': 14, 'ORGANIZATION': 15, 'DEPARTMENT': 16, 'STATE': 17, 'DOCTOR': 18, 'LOCATION-OTHER': 19, 'CITY': 20, 'SET': 21}\n"
     ]
    }
   ],
   "source": [
    "#add special token [other] in label list\n",
    "labels_type = list(set( [label[0] for labels in train_label_dict.values() for label in labels] ))\n",
    "labels_type = [\"OTHER\"] + labels_type \n",
    "labels_num = len(labels_type)\n",
    "# print(labels_type)\n",
    "# print(\"The number of labels:\", labels_num)\n",
    "labels_type_table = {label_name:id for id, label_name in enumerate(labels_type)}\n",
    "print(labels_type_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "293ec476",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OTHER': 0, 'PATIENT': 1, 'DOCTOR': 2, 'CITY': 3, 'ROOM': 4, 'STREET': 5, 'MEDICALRECORD': 6, 'DEPARTMENT': 7, 'LOCATION-OTHER': 8, 'COUNTRY': 9, 'IDNUM': 10, 'STATE': 11, 'AGE': 12, 'SET': 13, 'HOSPITAL': 14, 'DATE': 15, 'ZIP': 16, 'URL': 17, 'DURATION': 18, 'ORGANIZATION': 19, 'TIME': 20, 'PHONE': 21}\n"
     ]
    }
   ],
   "source": [
    "# fix it\n",
    "labels_type_table={'OTHER': 0, 'PATIENT': 1, 'DOCTOR': 2, 'CITY': 3, 'ROOM': 4, 'STREET': 5, 'MEDICALRECORD': 6, 'DEPARTMENT': 7, 'LOCATION-OTHER': 8, 'COUNTRY': 9, 'IDNUM': 10, 'STATE': 11, 'AGE': 12, 'SET': 13, 'HOSPITAL': 14, 'DATE': 15, 'ZIP': 16, 'URL': 17, 'DURATION': 18, 'ORGANIZATION': 19, 'TIME': 20, 'PHONE': 21}\n",
    "print(labels_type_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4eb4053f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check the label_type is enough for validation\n",
    "val_labels_type = list(set( [label[0] for labels in val_label_dict.values() for label in labels] ))\n",
    "for val_label_type in val_labels_type:\n",
    "    if val_label_type not in labels_type:\n",
    "        print(\"Special label in validation:\", val_label_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21771ea9",
   "metadata": {},
   "source": [
    "### Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "961e442d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"allenai/longformer-base-4096\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eef8f925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LongformerModel\n",
    "from torchcrf import CRF\n",
    "\n",
    "class MyLongformerModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom PyTorch model using the Longformer architecture with Conditional Random Fields (CRF) for sequence labeling.\n",
    "\n",
    "    Parameters:\n",
    "    - num_labels (int): The number of unique labels/classes for sequence labeling.\n",
    "\n",
    "    Attributes:\n",
    "    - longformer (LongformerModel): Pre-trained Longformer model.\n",
    "    - dropout (nn.Dropout): Dropout layer to prevent overfitting.\n",
    "    - classifier (nn.Linear): Linear layer for classification.\n",
    "    - crf (CRF): Conditional Random Field layer for sequence labeling.\n",
    "\n",
    "    Methods:\n",
    "    - forward(input_ids, attention_mask, labels=None): Forward pass of the model.\n",
    "\n",
    "    Example Usage:\n",
    "    ```python\n",
    "    model = MyLongformerModel(num_labels=22)\n",
    "    ```\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_labels):\n",
    "        \"\"\"\n",
    "        Initializes the MyLongformerModel.\n",
    "\n",
    "        Parameters:\n",
    "        - num_labels (int): The number of unique labels/classes for sequence labeling.\n",
    "        \"\"\"\n",
    "        super(MyLongformerModel, self).__init__()\n",
    "\n",
    "        # Pre-trained Longformer model\n",
    "        self.longformer = LongformerModel.from_pretrained('allenai/longformer-base-4096')\n",
    "\n",
    "        # Dropout layer to prevent overfitting\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "        # Linear layer for classification\n",
    "        self.classifier = nn.Linear(768, num_labels)\n",
    "\n",
    "        # Conditional Random Field layer for sequence labeling\n",
    "        self.crf = CRF(num_labels, batch_first=True)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        \"\"\"\n",
    "        Forward pass of the MyLongformerModel.\n",
    "\n",
    "        Parameters:\n",
    "        - input_ids (torch.Tensor): Input tensor containing token IDs.\n",
    "        - attention_mask (torch.Tensor): Attention mask tensor indicating which tokens should be attended to.\n",
    "        - labels (torch.Tensor): Ground truth labels for sequence labeling. If None, decoding is performed.\n",
    "\n",
    "        Returns:\n",
    "        - loss (torch.Tensor) if labels are provided, else decoded sequence labels (torch.Tensor).\n",
    "        \"\"\"\n",
    "        outputs = self.longformer(input_ids=input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "        sequence_output = self.dropout(outputs.last_hidden_state)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = -self.crf(logits, labels, mask=attention_mask.byte())\n",
    "            return loss\n",
    "        else:\n",
    "            return self.crf.decode(logits, mask=attention_mask.byte())\n",
    "\n",
    "# Usage\n",
    "model = MyLongformerModel(num_labels=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bb2cf94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BACH_SIZE = 4\n",
    "#TRAIN_RATIO = 0.9\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b49e00",
   "metadata": {},
   "source": [
    "### dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81b73a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class PrivacyProtectionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset class for privacy protection tasks with medical records.\n",
    "\n",
    "    Parameters:\n",
    "    - medical_record_dict (dict): A dictionary containing medical record IDs as keys and text content as values.\n",
    "    - medical_record_labels (dict): A dictionary containing medical record IDs as keys and lists of labels as values.\n",
    "    - tokenizer: Tokenizer for encoding the text.\n",
    "    - labels_type_table (dict): A dictionary mapping label types to numerical IDs.\n",
    "    - mode (str): Mode of the dataset, e.g., 'train', 'test', or 'val'.\n",
    "\n",
    "    Attributes:\n",
    "    - max_length (int): Maximum length for text chunks.\n",
    "    - labels_type_table (dict): A dictionary mapping label types to numerical IDs.\n",
    "    - tokenizer: Tokenizer for encoding the text.\n",
    "    - data (list): A list containing tuples of text chunks, corresponding labels, and record IDs.\n",
    "\n",
    "    Methods:\n",
    "    - split_and_add_data(text, labels, id): Splits text into chunks and adds data to the dataset.\n",
    "    - __getitem__(index): Returns a tuple containing text chunk, labels, and record ID for a given index.\n",
    "    - __len__(): Returns the total number of items in the dataset.\n",
    "    - find_token_ids(label_start, label_end, offset_mapping): Finds token IDs corresponding to label positions after tokenization.\n",
    "    - encode_labels_position(batch_labels, offset_mapping): Encodes the positions of labels in tokenized text.\n",
    "    - create_labels_tensor(batch_shape, batch_labels_position_encoded): Creates a tensor representing labels for the batch.\n",
    "    - collate_fn(batch_items): Collates a batch of items during data loading.\n",
    "\n",
    "    Example Usage:\n",
    "    ```python\n",
    "    dataset = PrivacyProtectionDataset(medical_record_dict, medical_record_labels, tokenizer, labels_type_table, mode='train')\n",
    "    dataloader = DataLoader(dataset, batch_size=32, collate_fn=dataset.collate_fn)\n",
    "    ```\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, medical_record_dict: dict, medical_record_labels: dict, tokenizer, labels_type_table: dict, mode: str):\n",
    "        \"\"\"\n",
    "        Initializes the PrivacyProtectionDataset.\n",
    "\n",
    "        Parameters:\n",
    "        - medical_record_dict (dict): A dictionary containing medical record IDs as keys and text content as values.\n",
    "        - medical_record_labels (dict): A dictionary containing medical record IDs as keys and lists of labels as values.\n",
    "        - tokenizer: Tokenizer for encoding the text.\n",
    "        - labels_type_table (dict): A dictionary mapping label types to numerical IDs.\n",
    "        - mode (str): Mode of the dataset, e.g., 'train', 'test', or 'val'.\n",
    "        \"\"\"\n",
    "        self.max_length = 4096\n",
    "        self.labels_type_table = labels_type_table\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = []\n",
    "\n",
    "        for id, text in medical_record_dict.items():\n",
    "            labels = medical_record_labels.get(id, [])\n",
    "            self.split_and_add_data(text, labels, id)\n",
    "\n",
    "    def split_and_add_data(self, text, labels, id):\n",
    "        \"\"\"\n",
    "        Splits the text into chunks and adds data to the dataset.\n",
    "\n",
    "        Parameters:\n",
    "        - text (str): The full text of the medical record.\n",
    "        - labels (list): A list of labels containing (id, start, end, expected_text).\n",
    "        - id (str): The identifier of the medical record.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        # Split text into chunks of max_length\n",
    "        for i in range(0, len(text), self.max_length):\n",
    "            text_chunk = text[i:i + self.max_length]\n",
    "            # Adjust labels for this chunk\n",
    "            chunk_labels = [label for label in labels if label[1] >= i and label[2] <= i + self.max_length]\n",
    "            chunk_labels = [[label[0], label[1] - i, label[2] - i] for label in chunk_labels]\n",
    "            self.data.append((text_chunk, chunk_labels, id))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Returns a tuple containing text chunk, labels, and record ID for a given index.\n",
    "\n",
    "        Parameters:\n",
    "        - index (int): Index of the item in the dataset.\n",
    "\n",
    "        Returns:\n",
    "        - tuple: A tuple containing text chunk, labels, and record ID.\n",
    "        \"\"\"\n",
    "        text_chunk, chunk_labels, id = self.data[index]\n",
    "        return text_chunk, chunk_labels, id\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of items in the dataset.\n",
    "\n",
    "        Returns:\n",
    "        - int: The total number of items in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def find_token_ids(self, label_start, label_end, offset_mapping):\n",
    "        \"\"\"\n",
    "        Finds token IDs corresponding to label positions after tokenization.\n",
    "\n",
    "        Parameters:\n",
    "        - label_start (int): Start position of the label.\n",
    "        - label_end (int): End position of the label.\n",
    "        - offset_mapping (list): List of token offset mappings.\n",
    "\n",
    "        Returns:\n",
    "        - tuple: A tuple containing the start and end token IDs.\n",
    "        \"\"\"\n",
    "        encode_start = float(\"inf\")  # max\n",
    "        encode_end = 0\n",
    "        for token_id, token_range in enumerate(offset_mapping):\n",
    "            token_start, token_end = token_range\n",
    "\n",
    "            # if token range one side out of label range, still take the token\n",
    "            if token_start == 0 and token_end == 0:  # special token\n",
    "                continue\n",
    "\n",
    "            if label_start < token_end and label_end > token_start:\n",
    "                if token_id < encode_start:\n",
    "                    encode_start = token_id\n",
    "                encode_end = token_id + 1\n",
    "\n",
    "        return encode_start, encode_end\n",
    "\n",
    "    def encode_labels_position(self, batch_labels: list, offset_mapping: list):\n",
    "        \"\"\"\n",
    "        Encodes the positions of labels in tokenized text.\n",
    "\n",
    "        Parameters:\n",
    "        - batch_labels (list): List of labels for a batch.\n",
    "        - offset_mapping (list): List of token offset mappings for the batch.\n",
    "\n",
    "        Returns:\n",
    "        - list: List of encoded label positions for the batch.\n",
    "        \"\"\"\n",
    "        batch_encoding_labels = []\n",
    "        for sample_labels, sample_offsets in zip(batch_labels, offset_mapping):\n",
    "            encoding_labels = []\n",
    "            for label in sample_labels:\n",
    "                encoding_start, encoding_end = self.find_token_ids(label[1], label[2], sample_offsets)\n",
    "                encoding_labels.append([label[0], encoding_start, encoding_end])\n",
    "            batch_encoding_labels.append(encoding_labels)\n",
    "        return batch_encoding_labels\n",
    "\n",
    "    def create_labels_tensor(self, batch_shape: list, batch_labels_position_encoded: list):\n",
    "        \"\"\"\n",
    "        Creates a tensor representing labels for the batch.\n",
    "\n",
    "        Parameters:\n",
    "        - batch_shape (list): Shape of the tensor to be created.\n",
    "        - batch_labels_position_encoded (list): List of encoded label positions for the batch.\n",
    "\n",
    "        Returns:\n",
    "        - torch.Tensor: Tensor representing labels for the batch.\n",
    "        \"\"\"\n",
    "        if batch_shape[-1] > self.max_length:\n",
    "            batch_shape[-1] = self.max_length\n",
    "        labels_tensor = torch.zeros(batch_shape)\n",
    "\n",
    "        for sample_id in range(batch_shape[0]):\n",
    "            for label in batch_labels_position_encoded[sample_id]:\n",
    "                label_id = self.labels_type_table[label[0]]\n",
    "                start = label[1]\n",
    "                end = label[2]\n",
    "\n",
    "                if start >= self.max_length:\n",
    "                    continue\n",
    "                elif end >= self.max_length:\n",
    "                    end = self.max_length\n",
    "\n",
    "                labels_tensor[sample_id][start:end] = label_id\n",
    "\n",
    "        return labels_tensor\n",
    "\n",
    "    def collate_fn(self, batch_items: list):\n",
    "        \"\"\"\n",
    "        Collates a batch of items during data loading.\n",
    "\n",
    "        Parameters:\n",
    "        - batch_items (list): List of items in the batch.\n",
    "\n",
    "        Returns:\n",
    "        - tuple: A tuple containing tokenized encodings, labels tensor, and original labels.\n",
    "        \"\"\"\n",
    "        # the calculation process in dataloader iteration\n",
    "        batch_medical_record = [sample[0] for sample in batch_items]\n",
    "        batch_labels = [sample[1] for sample in batch_items]\n",
    "        batch_id_list = [sample[2] for sample in batch_items]\n",
    "\n",
    "        encodings = self.tokenizer(batch_medical_record, padding=True, truncation=True, return_tensors=\"pt\",\n",
    "                                   return_offsets_mapping=True)  # truncation=True\n",
    "\n",
    "        batch_labels_position_encoded = self.encode_labels_position(batch_labels, encodings[\"offset_mapping\"])\n",
    "        batch_labels_tensor = self.create_labels_tensor(encodings[\"input_ids\"].shape, batch_labels_position_encoded)\n",
    "\n",
    "        return encodings, batch_labels_tensor, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a2ae1c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_id_list = list(train_medical_record_dict.keys())\n",
    "train_medical_record = {sample_id: train_medical_record_dict[sample_id] for sample_id in train_id_list}\n",
    "train_labels = {sample_id: train_label_dict[sample_id] for sample_id in train_id_list}\n",
    "\n",
    "val_id_list = list(val_medical_record_dict.keys())\n",
    "val_medical_record = {sample_id: val_medical_record_dict[sample_id] for sample_id in val_id_list}\n",
    "val_labels = {sample_id: val_label_dict[sample_id] for sample_id in val_id_list}\n",
    "\n",
    "train_dataset = Privacy_protection_dataset(train_medical_record, train_labels, tokenizer, labels_type_table, \"train\")\n",
    "val_dataset = Privacy_protection_dataset(val_medical_record, val_labels, tokenizer, labels_type_table, \"validation\")\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader( train_dataset, batch_size = BACH_SIZE, shuffle = True, collate_fn = train_dataset.collate_fn)\n",
    "val_dataloader = DataLoader( val_dataset, batch_size = BACH_SIZE, shuffle = False, collate_fn = val_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5241490",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "031f0ae8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = model.to(device) # Put model on device\n",
    "optim = AdamW(model.parameters(), lr = LEARNING_RATE)\n",
    "#if use CRF\n",
    "#loss_fct = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6679b81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def decode_model_result(model_predict_list, offsets_mapping, labels_type_table):\n",
    "    \"\"\"\n",
    "    Decode the model predictions into labeled entities.\n",
    "\n",
    "    Parameters:\n",
    "    - model_predict_list (list): List of predicted label IDs.\n",
    "    - offsets_mapping (list): List of offset mappings obtained from tokenization.\n",
    "    - labels_type_table (dict): Dictionary mapping label types to their corresponding numerical identifiers.\n",
    "\n",
    "    Returns:\n",
    "    - list: List of decoded labeled entities.\n",
    "    \"\"\"\n",
    "    id_to_label = {id: label for label, id in labels_type_table.items()}\n",
    "    predict_y = []\n",
    "    pre_label_id = 0\n",
    "    start = 0\n",
    "\n",
    "    for position_id, label_id in enumerate(model_predict_list):\n",
    "        if label_id != 0:\n",
    "            if pre_label_id != label_id:\n",
    "                start = int(offsets_mapping[position_id][0])\n",
    "            end = int(offsets_mapping[position_id][1])\n",
    "\n",
    "        if pre_label_id != label_id and pre_label_id != 0:\n",
    "            predict_y.append([id_to_label[pre_label_id], start, end])\n",
    "        pre_label_id = label_id\n",
    "\n",
    "    if pre_label_id != 0:\n",
    "        predict_y.append([id_to_label[pre_label_id], start, end])\n",
    "\n",
    "    return predict_y\n",
    "\n",
    "def calculate_batch_score(batch_labels, model_predict_sequences, offset_mappings, labels_type_table):\n",
    "    \"\"\"\n",
    "    Calculate TP, FP, and FN for each label in a batch.\n",
    "\n",
    "    Parameters:\n",
    "    - batch_labels (list): List of ground truth labels for a batch.\n",
    "    - model_predict_sequences (list): List of predicted label sequences for a batch.\n",
    "    - offset_mappings (list): List of offset mappings obtained from tokenization.\n",
    "    - labels_type_table (dict): Dictionary mapping label types to their corresponding numerical identifiers.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A nested dictionary containing TP, FP, and FN scores for each label.\n",
    "    \"\"\"\n",
    "    score_table = defaultdict(lambda: {\"TP\": 0, \"FP\": 0, \"FN\": 0})\n",
    "    id_to_label = {id: label for label, id in labels_type_table.items()}\n",
    "    batch_size = len(model_predict_sequences)\n",
    "\n",
    "    for batch_id in range(batch_size):\n",
    "        sample_prediction = decode_model_result(model_predict_sequences[batch_id], offset_mappings[batch_id], labels_type_table)\n",
    "        sample_ground_truth = batch_labels[batch_id]\n",
    "\n",
    "        # convert ground truth and predictions to sets for comparison\n",
    "        sample_ground_truth = set([tuple(token) for token in sample_ground_truth])\n",
    "        sample_prediction = set([tuple(token) for token in sample_prediction])\n",
    "\n",
    "        # calculate TP, FP, FN for each label\n",
    "        for label_id in labels_type_table.values():\n",
    "            label = id_to_label[label_id]\n",
    "            gt_entities = {x for x in sample_ground_truth if x[0] == label}\n",
    "            pred_entities = {x for x in sample_prediction if x[0] == label}\n",
    "\n",
    "            score_table[label][\"TP\"] += len(gt_entities & pred_entities)\n",
    "            score_table[label][\"FP\"] += len(pred_entities - gt_entities)\n",
    "            score_table[label][\"FN\"] += len(gt_entities - pred_entities)\n",
    "\n",
    "    return score_table\n",
    "\n",
    "def calculate_macro_f1(score_table):\n",
    "    \"\"\"\n",
    "    Calculate macro-averaged Precision, Recall, and F1 Score.\n",
    "\n",
    "    Parameters:\n",
    "    - score_table (dict): A nested dictionary containing TP, FP, and FN scores for each label.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Macro-averaged Precision, Recall, and F1 Score.\n",
    "    \"\"\"\n",
    "    macro_precision = macro_recall = macro_f1 = 0\n",
    "    num_labels = len(score_table)\n",
    "\n",
    "    for label, scores in score_table.items():\n",
    "        precision = scores[\"TP\"] / (scores[\"TP\"] + scores[\"FP\"]) if scores[\"TP\"] + scores[\"FP\"] > 0 else 0\n",
    "        recall = scores[\"TP\"] / (scores[\"TP\"] + scores[\"FN\"]) if scores[\"TP\"] + scores[\"FN\"] > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "        macro_precision += precision\n",
    "        macro_recall += recall\n",
    "        macro_f1 += f1\n",
    "\n",
    "    return macro_precision / num_labels, macro_recall / num_labels, macro_f1 / num_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "949a8ef9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorCompare.cpp:519.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Train Loss: 223.257924\n",
      "Epoch 0 - Macro Precision: 0.576980, Macro Recall: 0.596096, Macro F1 Score: 0.584692\n",
      "Epoch 1 - Train Loss: 21.471636\n",
      "Epoch 1 - Macro Precision: 0.627141, Macro Recall: 0.639088, Macro F1 Score: 0.631008\n",
      "Epoch 2 - Train Loss: 16.164490\n",
      "Epoch 2 - Macro Precision: 0.661379, Macro Recall: 0.672359, Macro F1 Score: 0.664760\n",
      "Epoch 3 - Train Loss: 15.499107\n",
      "Epoch 3 - Macro Precision: 0.654168, Macro Recall: 0.710479, Macro F1 Score: 0.673221\n",
      "Epoch 4 - Train Loss: 17.719697\n",
      "Epoch 4 - Macro Precision: 0.633542, Macro Recall: 0.679608, Macro F1 Score: 0.652611\n",
      "Epoch 5 - Train Loss: 11.341971\n",
      "Epoch 5 - Macro Precision: 0.663300, Macro Recall: 0.691600, Macro F1 Score: 0.674654\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m model(input_ids, attention_mask, labels)\n\u001b[1;32m     16\u001b[0m     total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     21\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m total_train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataloader)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:491\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    483\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    484\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    490\u001b[0m     )\n\u001b[0;32m--> 491\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train and validate a deep learning model for privacy protection using a custom dataset.\n",
    "\n",
    "Parameters:\n",
    "- EPOCH (int): Number of training epochs.\n",
    "- model (torch.nn.Module): The deep learning model to be trained.\n",
    "- train_dataloader (torch.utils.data.DataLoader): DataLoader for the training dataset.\n",
    "- val_dataloader (torch.utils.data.DataLoader): DataLoader for the validation dataset.\n",
    "- optim (torch.optim.Optimizer): The optimizer for updating model parameters during training.\n",
    "- device (torch.device): Device on which the model and data reside (e.g., \"cuda\" or \"cpu\").\n",
    "- labels_type_table (dict): A mapping of label names to corresponding numerical identifiers.\n",
    "\"\"\"\n",
    "\n",
    "train_step = 0\n",
    "val_step = 0\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    \"\"\"\n",
    "    Training loop for each epoch.\n",
    "\n",
    "    Parameters:\n",
    "    - epoch (int): Current epoch number.\n",
    "    \"\"\"\n",
    "\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch_x, batch_y, batch_labels in train_dataloader:\n",
    "        \"\"\"\n",
    "        Training iteration over the batches in the training dataset.\n",
    "\n",
    "        Parameters:\n",
    "        - batch_x (dict): Input features for the batch.\n",
    "        - batch_y (torch.Tensor): Ground truth labels for the batch.\n",
    "        - batch_labels (list): True label information for each token in the batch.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "\n",
    "        train_step += 1\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch_x[\"input_ids\"].to(device)\n",
    "        attention_mask = batch_x[\"attention_mask\"].to(device)\n",
    "        labels = batch_y.long().to(device)\n",
    "\n",
    "        loss = model(input_ids, attention_mask, labels)\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch} - Train Loss: {avg_train_loss:.6f}\")\n",
    "\n",
    "    model.eval()\n",
    "    total_score_table = defaultdict(lambda: {\"TP\": 0, \"FP\": 0, \"FN\": 0})\n",
    "\n",
    "    for batch_x, batch_y, batch_labels in val_dataloader:\n",
    "        \"\"\"\n",
    "        Validation iteration over the batches in the validation dataset.\n",
    "\n",
    "        Parameters:\n",
    "        - batch_x (dict): Input features for the batch.\n",
    "        - batch_y (torch.Tensor): Ground truth labels for the batch.\n",
    "        - batch_labels (list): True label information for each token in the batch.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "\n",
    "        batch_x[\"input_ids\"] = batch_x[\"input_ids\"].to(device)\n",
    "        batch_x[\"attention_mask\"] = batch_x[\"attention_mask\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_predict_sequences = model(batch_x[\"input_ids\"], batch_x[\"attention_mask\"])\n",
    "            batch_score_table = calculate_batch_score(\n",
    "                batch_labels, model_predict_sequences, batch_x[\"offset_mapping\"], labels_type_table\n",
    "            )\n",
    "\n",
    "            for label, scores in batch_score_table.items():\n",
    "                for key in total_score_table[label]:\n",
    "                    total_score_table[label][key] += scores[key]\n",
    "\n",
    "    avg_precision, avg_recall, avg_macro_f1 = calculate_macro_f1(total_score_table)\n",
    "    print(f\"Epoch {epoch} - Macro Precision: {avg_precision:.6f}, Macro Recall: {avg_recall:.6f}, Macro F1 Score: {avg_macro_f1:.6f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), \"./model/\" + \"longformer\" + \"_\" + str(epoch) + \"_\" + str(avg_macro_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1a1bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total_score_table = defaultdict(lambda: {\"TP\": 0, \"FP\": 0, \"FN\": 0})\n",
    "\n",
    "for batch_x, batch_y, batch_labels in val_dataloader:\n",
    "    batch_x[\"input_ids\"] = batch_x[\"input_ids\"].to(device)\n",
    "    batch_x[\"attention_mask\"] = batch_x[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_predict_sequences = model(batch_x[\"input_ids\"], batch_x[\"attention_mask\"])\n",
    "        batch_score_table = calculate_batch_score(batch_labels, model_predict_sequences, batch_x[\"offset_mapping\"], labels_type_table)\n",
    "        for label, scores in batch_score_table.items():\n",
    "            for key in total_score_table[label]:\n",
    "                total_score_table[label][key] += scores[key]\n",
    "\n",
    "avg_precision, avg_recall, avg_macro_f1 = calculate_macro_f1(total_score_table)\n",
    "print(f\"Epoch {epoch} - Macro Precision: {avg_precision:.6f}, Macro Recall: {avg_recall:.6f}, Macro F1 Score: {avg_macro_f1:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
